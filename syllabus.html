<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Syllabus and Textbooks</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">COMP5800</div>
<div class="menu-item"><a href=".">Home</a></div>
<div class="menu-item"><a href="syllabus.html" class="current">Syllabus</a></div>
<div class="menu-item"><a href="grading.html">Grading</a></div>
<div class="menu-item"><a href="policies.html">Policies</a></div>
<div class="menu-item"><a href="assignments.html">Assignments</a></div>
<div class="menu-item"><a href="resources.html">Resources</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Syllabus and Textbooks</h1>
</div>
<p>The required reading will be mainly from select journal/conference articles (listed below for each lecture), which are all available online. The following books are recommended as well: </p>
<ul>
<li><p>[<b>GRL</b>] <a target='_new' href="https://www.cs.mcgill.ca/~wlh/grl_book/">Graph Representation Learning</a><br />
William L. Hamilton</p>
</li>
</ul>
<ul>
<li><p>[<b>NCM</b>] <a target='_new' href="http://www.cs.cornell.edu/home/kleinber/networks-book/">Networks, Crowds, and Markets: Reasoning About a Highly Connected World</a><br />
David Easley and Jon Kleinberg</p>
</li>
</ul>
<h2>Syllabus </h2>
<p>GRL and NCM indicate the above texts. Slides, lecture ntoes and other materials will be available on <a target='_new' href="https://uml.umassonline.net/webapps/login/">Blackboard</a>.</p>
<table id="syllabus">
<tr class="r1"><td class="c1"><b> W01: Sep 2 </b>	</td><td class="c2"> <b> Introduction and Graph Basics</b> </td><td class="c2"> 	<b><a target='_new' href="files/info.pdf">Lecture 0</a>,<a target='_new' href="files/intro.pdf">1</a>,<a target='_new' href="files/basics.pdf">2</a> </b> </td></tr>
<tr class="r5"><td class="c1"></td><td class="c2"> Ch.01 Introduction [GRL]<br /> Ch.02 Graphs [NCM] </td><td class="c2"> </td></tr>
<tr class="r10"><td class="c1">
<b> W02: Sep 9 </b>	</td><td class="c2"> <b> Graph Properties and Features </b>	</td><td class="c2"></td></tr>
<tr class="r14"><td class="c1"> </td><td class="c2"> Ch.02 Background and Traditional Approaches  [GRL]<br /> Ch.03 Strong and Weak Ties [NCM]<br />Ch.13 The Structure of the Web [NCM]<br />Searching for superspreaders of information in real-world social media. Pei, S., et al. Scientific reports&rsquo;14.<br />Fragile online relationship: a first look at unfollow dynamics in twitter. Kwak, H., et al. SIGCHI&rsquo;11.<br />Structure and tie strengths in mobile communication networks. Onnela, J.P., et al. PNAS&rsquo;07.<br />Graph structure in the web. Broder, A., et al. Computer networks&rsquo;00. <br />
<img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: Crawling data from large scale networks. <br /></td><td class="c2"> </td></tr>
<tr class="r24"><td class="c1">
<b> W03: Sep 16	</b> 	</td><td class="c2"><b> Node Embeddings 1</b> 	</td><td class="c2"> </td></tr>
<tr class="r28"><td class="c1"></td><td class="c2">Ch.03 Neighborhood Reconstruction Method [GRL]<br /> Retrofitting word vectors to semantic lexicons. Faruqui, M., et al. NAACL&rsquo;15.<br />Glove: global vectors for word representation. Pennington, J., et al. EMNLP&rsquo;14. <br />Distributed representations of words and phrases and their compositionality. Mikolov, T., et al. NIPS&rsquo;13.<br />
<img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: Distributional semantics. <br /></td><td class="c2"> </td></tr>
<tr class="r36"><td class="c1">
<b> W04: Sep 23	</b> 	</td><td class="c2"><b> Node Embeddings 2 </b> 	</td><td class="c2"> </td></tr>
<tr class="r40"><td class="c1"></td><td class="c2"> Ch.03 Neighborhood Reconstruction Method [GRL]<br /> Node2vec: scalable feature learning for networks. Grover, A. and Leskovec, J. SIGKDD&rsquo;16.<br />Deepwalk: online learning of social representations. Perozzi, B., et al. SIGKDD&rsquo;14.<br /><a target='_new' href="https://youtu.be/YrhBZUtgG4E"><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"></a> Course Lecture: <a target='_new' href="https://youtu.be/YrhBZUtgG4E">Graph Representation Learning</a>. Leskovec J. 2019. <br /><a target='_new' href="https://www.youtube.com/watch?v=yG4XbgytH4w"><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"></a> AI2 talk: <a target='_new' href="https://www.youtube.com/watch?v=yG4XbgytH4w">Beyond the Distributional Hypothesis: Learning Better Word Representations</a>. Manaal F. 2016. </td><td class="c2"> </td></tr>
<tr class="r47"><td class="c1">
<b> W05: Sep 30	</b> 	</td><td class="c2"><b> Graph Neural Networks 1 </b> 	</td><td class="c2"> </td></tr>
<tr class="r51"><td class="c1"></td><td class="c2">Ch.05 The Graph Neural Network Model [GRL]<br />Inductive representation learning on large graphs. Hamilton, W., et al. NIPS&rsquo;17.<br />Semi-supervised classification with graph convolutional networks. Kipf, T.N., et al. ICLR&rsquo;17.<br />Learning convolutional neural networks for graphs. Niepert, M., et al. ICML&rsquo;16.<br />
<img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: GraphSAGE.</td><td class="c2"> </td></tr>
<tr class="r59"><td class="c1">
<b> W06: Oct 7 </b> 	</td><td class="c2"><b> Graph Neural Networks 2 </b> 	</td><td class="c2"> </td></tr>
<tr class="r63"><td class="c1"></td><td class="c2">Ch.05 The Graph Neural Network Model [GRL]<br />Random walk graph neural networks. Giannis, N. et al. NeurIPS&rsquo;20<br />Strategies for pre-training graph neural networks. Hu, Weihua, et al. ICLR&rsquo;20.<br /></td><td class="c2"> </td></tr>
<tr class="r68"><td class="c1">
<b> W07: Oct 14</b> 	</td><td class="c2"><b> Exam!</b> </td><td class="c2"> </td></tr>
<tr class="r71"><td class="c1"></td><td class="c2"> Open book exam </td><td class="c2"> </td></tr>
<tr class="r74"><td class="c1">
<b> W08: Oct 21 </b> </td><td class="c2"><b> Link Prediction</b> 	</td><td class="c2"> </td></tr>
<tr class="r78"><td class="c1"></td><td class="c2">Ch.05 Positive and Negative Relationships [NCM]<br />How to hide one's relationships from link prediction algorithms. Waniek, M., et al. Scientific reports&rsquo;19.<br />Modeling polypharmacy side effects with GNNs. Zitnik, M., et al. Bioinformatics&rsquo;18.<br />Exploiting social network structure for person-to-person sentiment analysis. Robert, et al. TACL&rsquo;14.<br />Predicting positive and negative links in online social networks. Leskovec, J. et al. WWW&rsquo;10.<br />
<img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: Link prediction.</td><td class="c2"> </td></tr>
<tr class="r86"><td class="c1">
<b> W09: Oct 28</b> 	</td><td class="c2"> <b> Cascade Prediction</b> 	</td><td class="c2"> </td></tr>
<tr class="r90"><td class="c1"></td><td class="c2"> Ch.16 Information Cascades [NCM]<br />Ch.19 Cascading Behavior in Networks [NCM]<br />Multi-winner contests for strategic diffusion in social networks. Shen, W., et al. AAAI&rsquo;19.<br />Do cascades recur? Cheng, J., et al. WWW&rsquo;16.<br />Emerging topic detection for organizations from microblogs. Chen, Y., et al. SIGIR&rsquo;13.<br />The anatomy of large facebook cascades. Alex, D., et al. ICWSM&rsquo;13.<br /><a target='_new' href="https://www.youtube.com/watch?v=lbCmFZpMNxA"><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"></a> Lecture: <a target='_new' href="https://www.youtube.com/watch?v=lbCmFZpMNxA">Information diffusion on Twitter</a>. Nikolov, S. 2012.<br /><a target='_new' href="https://www.ted.com/talks/derek_sivers_how_to_start_a_movement"><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"></a> TED talk: <a target='_new' href="https://www.ted.com/talks/derek_sivers_how_to_start_a_movement">How to start a movement</a>. Sivers, D. 2010. </td><td class="c2"> </td></tr>
<tr class="r100"><td class="c1">
<b> W10: Nov 4 </b> 	</td><td class="c2"> <b> Power Laws and Popularity</b> 	</td><td class="c2"> </td></tr>
<tr class="r104"><td class="c1"></td><td class="c2">Ch.18 Power Laws and Rich-Get-Richer Phenomena [NCM]<br />Ch.14 Link Analysis and Web search [NCM]<br />The anatomy of the facebook social graph. Ugander, J., et al. arXiv&rsquo;11.<br />Inequality and unpredictability in an artificial cultural market. Salganik, M.J., et al. Science&rsquo;06.<br />The small world problem . Milgram S. Psychology Today&rsquo;1967.<br /><a target='_new' href="https://www.youtube.com/playlist?list=PL2DB408AF84F66CD9"><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"></a> Documentary: <a target='_new' href="https://www.youtube.com/playlist?list=PL2DB408AF84F66CD9">Connected: the power of six degrees</a>. A documentary on networks, social and otherwise. 2008. </td><td class="c2"> </td></tr>
<tr class="r112"><td class="c1">
<b> W11: Nov 11 </b> 	</td><td class="c2"> <b> no class!</b> </td><td class="c2"> </td></tr>
<tr class="r115"><td class="c1"></td><td class="c2"> Veteran's Day (university closed)</td><td class="c2"> </td></tr>
<tr class="r118"><td class="c1">
<b> W12: Nov 18	</b> 	</td><td class="c2"><b> Meta Learning with Graphs 1</b> 	</td><td class="c2"> </td></tr>
<tr class="r122"><td class="c1"></td><td class="c2"> Neural self-training through spaced repetition. Amiri H. NAACL&rsquo;19.<br />Mentornet: Learning data-driven curriculum for very DNNs on corrupted labels. Lu, J., et al. ICML&rsquo;18.<br />Spaced repetition for efficient and effective training of neural networks. Amiri H., et al. EMNLP&rsquo;17.<br />Self-paced curriculum learning. Lu, J., et al. AAAI&rsquo;15.<br />Curriculum learning. Yoshua, B. et al. ICML&rsquo;09.<br />
<img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: Leitner system.</td><td class="c2"> </td></tr>
<tr class="r131"><td class="c1">
<b> W13: Nov 25 </b> 	</td><td class="c2"> <b> no class</b> 	</td><td class="c2"> </td></tr>
<tr class="r134"><td class="c1"></td><td class="c2">Thanksgiving Recess</td><td class="c2"> </td></tr>
<tr class="r137"><td class="c1">
<b> W13: Dec 2</b> 	</td><td class="c2"><b> Meta Learning with Graphs 2</b> 	</td><td class="c2"> </td></tr>
<tr class="r141"><td class="c1"></td><td class="c2"> CurGraph: curriculum learning for graph classification. Wang, Yiwei, et al. WWW&rsquo;21.<br />Curriculum learning by dynamic instance hardness. Zhou, T., et al. NeurIPS&rsquo;20. <br /> SuperLoss: a generic loss for robust curriculum learning. Castells, et al. NeurIPS&rsquo;20.<br />Multi-Modal curriculum learning over graphs. Chen, G., et al. TIST&rsquo;19</td><td class="c2"> </td></tr>
<tr class="r147"><td class="c1">
<b> W14: Dec 9</b> 	</td><td class="c2"><b> Project presentations</b> 	</td><td class="c2"></td></tr>
<tr class="r150"><td class="c1"></td><td class="c2"> Project presentations. </td><td class="c2">
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2021-09-02 13:04:19 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
